{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQbsdkijrNo6"
   },
   "source": [
    "Everything here should ernd up ebing in its own function, split by cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyeNlrnKq8-G"
   },
   "outputs": [],
   "source": [
    "# CONFIG FILE PARAMETERS\n",
    "data_path = \"../data/\"\n",
    "random_seed = ...\n",
    "output_filepath = \"../data/\"\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPzJB4h4tZlJ"
   },
   "source": [
    "# Utility functions\n",
    "Function to be used by any file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZCxEYFhtisX"
   },
   "outputs": [],
   "source": [
    "# Plot a given set of data (try and abstract this to handle all plot calls for\n",
    "# a given type of plot.)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inplacify(func):\n",
    "    \"\"\"Decorates a function to implement inplace changes to a mutable\n",
    "    or returns a copy of the mutable with the changes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : Callable\n",
    "        The function to add the inplace functionality.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Callable\n",
    "        Wrapped function with the inplace functionality.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # get the inplace keyword argument value\n",
    "        inplace = kwargs.pop(\"inplace\", True)\n",
    "        if inplace:\n",
    "            # inplace modifies all mutables that are changed inside func \n",
    "            func(*args, **kwargs)\n",
    "        else:\n",
    "            # make a copy of the first positional argument, i.e, assume this is the mutable to keep unchanged\n",
    "            acopy = deepcopy(args[0])\n",
    "            # returns the function applied to the copy and the rest of the arguments\n",
    "            return func(acopy, *args[1:], **kwargs)\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJaQrRkexfnt"
   },
   "outputs": [],
   "source": [
    "# Output function(s) which supports needde types of outputs (csv, json, ...)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOwaQpblqv3D"
   },
   "source": [
    "# Loading the data\n",
    "\n",
    "**At this point we are not considering the sampling weights which are not identical for all individuals in the PUMF then the estimates calculated using this dataare not representative of the (survey) population.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import ydata_profiling\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Tested with ydata_profiling v4.5.1, pickle v4.0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata_profiling.__version__, pickle.format_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQc4empHqsGo"
   },
   "outputs": [],
   "source": [
    "def load_cchs_smk(data_path):\n",
    "    \"\"\"Load CCHS SMOKE data dictionary pickled file from data_path\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : str\n",
    "        The path for the pickle file CCHS_SMK.pkl\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with CCHS PUMF SMOKE dataframe, with datatypes and categorical features.\n",
    "        For instance, data_dict['dtypes']['GEO_PRV'] contains datatype = int64.\n",
    "        data_dict['cat']['GEO_PRV'] the possible values as in the original data.\n",
    "        data_dict['dataframe']['GEO_PRV'] the dataframe for this column with ADM_RNO as index.\n",
    "    \"\"\"\n",
    "    with open(data_path+\"CCHS_SMK.pkl\", \"rb\") as f:\n",
    "        data_dict = pickle.load(f)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_cchs_smk(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary checks\n",
    "\n",
    "### Provinces\n",
    "Remap provinces to sequential codes and compare to PUMF documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplacify\n",
    "def remap_provinces(data_dict, inplace=True):\n",
    "    \"\"\"Remap provinces to sequential codes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict : dict\n",
    "        A modified dictionary with CCHS PUMF SMOKE dataframe, with datatypes and categorical features.\n",
    "        For instance, data_dict['dtypes']['GEO_PRV'] contains datatype = int64.\n",
    "        data_dict['cat']['GEO_PRV'] the possible values as in the original data.\n",
    "        data_dict['dataframe']['GEO_PRV'] the dataframe for this column with ADM_RNO as index.\n",
    "\n",
    "    inplace : bool\n",
    "        Change data_dict if inplace is True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        If inplace is False returns a new data_dict modified.\n",
    "    \"\"\"\n",
    "    provinces_dict ={}\n",
    "    provinces_map = {}\n",
    "    # original order of codes in terms of provinces names\n",
    "    provinces = [\"NEWFOUNDLAND AND LABRADOR\",\n",
    "                 \"PRINCE EDWARD ISLAND\",\n",
    "                 \"NOVA SCOTIA\",\n",
    "                 \"NEW BRUNSWICK\",\n",
    "                 \"QUEBEC\",\n",
    "                 \"ONTARIO\",\n",
    "                 \"MANITOBA\",\n",
    "                 \"SASKATCHEWAN\",\n",
    "                 \"ALBERTA\",\n",
    "                 \"BRITISH COLUMBIA\",\n",
    "                 \"YUKON\",\n",
    "                 \"NORTHWEST TERRITORIES\",\n",
    "                 \"NUNAVUT\"]\n",
    "    for i, (k, p) in enumerate(zip(sorted(data_dict[\"cat\"][\"GEO_PRV\"]), provinces)):\n",
    "        provinces_dict[i] = p\n",
    "        provinces_map[k] = i\n",
    "    \n",
    "    # remap provinces codes\n",
    "    data_dict[\"dataframe\"][\"GEO_PRV\"] = data_dict[\"dataframe\"][\"GEO_PRV\"].map(provinces_map)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_test = remap_provinces(data_dict, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_test[\"dataframe\"][\"GEO_PRV\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's compare with original PUMF documentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[\"dataframe\"][\"GEO_PRV\"].value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Provinces](./img/provinces.png \"Provinces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves that the data based on provinces was loaded correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Health regions\n",
    "Repeat process above with health regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@inplacify\n",
    "def map_regions(data_dict, inplace=True):\n",
    "    \"\"\"Remap health regions to sequential codes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict : dict\n",
    "        A modified dictionary with CCHS PUMF SMOKE dataframe, with datatypes and categorical features.\n",
    "        For instance, data_dict['dtypes']['GEO_PRV'] contains datatype = int64.\n",
    "        data_dict['cat']['GEO_PRV'] the possible values as in the original data.\n",
    "        data_dict['dataframe']['GEO_PRV'] the dataframe for this column with ADM_RNO as index.\n",
    "\n",
    "    inplace : bool\n",
    "        Change data_dict if inplace is True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        If inplace is False returns a new data_dict modified.\n",
    "    \"\"\"\n",
    "    # read the health regions from file (same order as PUMF)\n",
    "    regions_df = pd.read_csv(data_path+\"health_regions.txt\", sep=\"+\", header=0, names=[\"Name\"])\n",
    "    regions_map = {}\n",
    "    for k, p in zip(sorted(data_dict[\"cat\"][\"GEODGHR4\"]), regions_df.index):\n",
    "        regions_map[k] = p\n",
    "    # remap regions codes\n",
    "    data_dict[\"dataframe\"][\"GEODGHR4\"] = data_dict[\"dataframe\"][\"GEODGHR4\"].map(regions_map)\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_regions(data_dict_test, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict[\"dataframe\"][\"GEODGHR4\"].value_counts().sort_index().head(12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![regions](./img/regions.png \"regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected column and mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read regions from file\n",
    "regions_dict = pd.read_csv(data_path+\"health_regions_orig.txt\", sep=\"+\", header=0, index_col=0).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary keyed by column name, with description and mappings Names to PUMF values\n",
    "var_map = {\n",
    "    \"GEO_PRV\": {\"description\": \"Province\", \"var_map\": {\n",
    "        \"NEWFOUNDLAND AND LABRADOR\": 10,\n",
    "        \"PRINCE EDWARD ISLAND\":      11,\n",
    "        \"NOVA SCOTIA\":               12,\n",
    "        \"NEW BRUNSWICK\":             13,\n",
    "        \"QUEBEC\":                    24,\n",
    "        \"ONTARIO\":                   35,\n",
    "        \"MANITOBA\":                  46,\n",
    "        \"SASKATCHEWAN\":              47,\n",
    "        \"ALBERTA\":                   48,\n",
    "        \"BRITISH COLUMBIA\":          59,\n",
    "        \"YUKON\":                     60,\n",
    "        \"NORTHWEST TERRITORIES\":     61,\n",
    "        \"NUNAVUT\":                   62}\n",
    "        },\n",
    "    \"GEODGHR4\": {\"description\": \"Province\", \"var_map\": regions_dict['Code']\n",
    "        },\n",
    "    \"DHH_SEX\": {\"description\": \"Sex\", \"var_map\": {\n",
    "        \"Male\": 1,\n",
    "        \"Female\": 2}\n",
    "        },\n",
    "    \"DHHGMS\": {\"description\": \"Marital Status\", \"var_map\": {\n",
    "        \"Married\":\t                    1,\n",
    "        \"Common-law\":\t                2,\n",
    "        \"Widowed/Divorced/Separated\":\t3,\n",
    "        \"Single\":\t                    4,\n",
    "        \"Not stated\":\t                9}\n",
    "        },\n",
    "    \"DHHGAGE\": {\"description\": \"Age\", \"var_map\": {\n",
    "        \"Age between 12 and 14\":\t1,\n",
    "        \"Age between 15 and 17\":\t2,\n",
    "        \"Age between 18 and 19\":\t3,\n",
    "        \"Age between 20 and 24\":\t4,\n",
    "        \"Age between 25 and 29\":\t5,\n",
    "        \"Age between 30 and 34\":\t6,\n",
    "        \"Age between 35 and 39\":\t7,\n",
    "        \"Age between 40 and 44\":\t8,\n",
    "        \"Age between 45 and 49\":\t9,\n",
    "        \"Age between 50 and 54\":\t10,\n",
    "        \"Age between 55 and 59\":\t11,\n",
    "        \"Age between 60 and 64\":\t12,\n",
    "        \"Age between 65 and 69\":\t13,\n",
    "        \"Age between 70 and 74\":\t14,\n",
    "        \"Age between 75 and 79\":\t15,\n",
    "        \"Age 80 and older\":\t16}\n",
    "        },\n",
    "    \"GEN_005\": {\"description\": \"Perceived health\", \"var_map\": {\n",
    "        \"Excellent\": 1,\n",
    "        \"Very good\": 2,\n",
    "        \"Good\":\t     3,\n",
    "        \"Fair\":\t     4,\n",
    "        \"Poor\":\t     5,\n",
    "        \"Don’t know\":7,\n",
    "        \"Refusal\":\t 8}\n",
    "        },    \n",
    "    \"GEN_015\": {\"description\": \"Perceived mental health\", \"var_map\": {\n",
    "        \"Excellent\": 1,\n",
    "        \"Very good\": 2,\n",
    "        \"Good\":\t     3,\n",
    "        \"Fair\":\t     4,\n",
    "        \"Poor\":\t     5,\n",
    "        \"Don’t know\":7,\n",
    "        \"Refusal\":\t 8,\n",
    "        \"Not stated\":9}\n",
    "        },\n",
    "    \"GEN_020\": {\"description\": \"Perceived life stress\", \"var_map\": {\n",
    "        \"Not at all stressful\":\t1,\n",
    "        \"Not very stressful\":\t2,\n",
    "        \"A bit stressful\":\t    3,\n",
    "        \"Quite a bit stressful\":4,\n",
    "        \"Extremely stressful\":\t5,\n",
    "        \"Don’t know\":\t        7,\n",
    "        \"Refusal\":\t            8}\n",
    "        },\n",
    "    \"GEN_025\": {\"description\": \"Perceived stress at work\", \"var_map\": {\n",
    "        \"Not at all stressful\":\t1,\n",
    "        \"Not very stressful\":\t2,\n",
    "        \"A bit stressful\":\t    3,\n",
    "        \"Quite a bit stressful\":4,\n",
    "        \"Extremely stressful\":\t5,\n",
    "        \"Valid skip\":\t        6,\n",
    "        \"Don’t know\":\t        7,\n",
    "        \"Refusal\":\t            8,\n",
    "        \"Not stated\":\t        9}\n",
    "        },\n",
    "    \"SMK_005\": {\"description\": \"Type of smoker (daily / occasionally / not at all) - presently\", \"var_map\": {\n",
    "        \"Daily\":\t    1,\n",
    "        \"Occasionally\":\t2,\n",
    "        \"Not at all\":\t3,\n",
    "        \"Don’t know\":\t7,\n",
    "        \"Refusal\":\t8}\n",
    "        },\n",
    "    \"SMK_015\": {\"description\": \"During the past 30 days, did you smoke every day?\", \"var_map\": {\n",
    "        \"Yes\":\t1,\n",
    "        \"No\":\t2,\n",
    "        \"Valid skip\":\t6,\n",
    "        \"Don’t know\":\t7,\n",
    "        \"Not stated\":\t9}\n",
    "        },\n",
    "    \"SMK_020\": {\"description\": \"Smoked more than 100 cigarettes - lifetime\", \"var_map\": {\n",
    "        \"Daily\":\t    1,\n",
    "        \"Occasionally\":\t2,\n",
    "        \"Not at all\":\t3,\n",
    "        \"Don’t know\":\t7,\n",
    "        \"Refusal\":\t8}\n",
    "        },\n",
    "    \"SMK_030\": {\"description\": \"Smoked daily - lifetime (occasional / former smoker)\", \"var_map\": {\n",
    "        \"Yes\":        \t1,\n",
    "        \"No\":\t        2,\n",
    "        \"Valid skip\":\t6,\n",
    "        \"Don’t know\":\t7,\n",
    "        \"Refusal\":\t    8,\n",
    "        \"Not stated\":\t9}\n",
    "       },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataframe from data_dict\n",
    "df = data_dict[\"dataframe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the extracted chunk from PUMF we have 67 columns and 113290 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_report(data_dict):\n",
    "    \"\"\"Make a report using ydata_profiling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict : dict\n",
    "        A modified dictionary with CCHS PUMF SMOKE dataframe, with datatypes and categorical features.\n",
    "        For instance, data_dict['dtypes']['GEO_PRV'] contains datatype = int64.\n",
    "        data_dict['cat']['GEO_PRV'] the possible values as in the original data.\n",
    "        data_dict['dataframe']['GEO_PRV'] the dataframe for this column with ADM_RNO as index.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The report in a python dict.\n",
    "\n",
    "    obj\n",
    "        The report object.\n",
    "    \"\"\"\n",
    "    df = data_dict[\"dataframe\"]\n",
    "    type_schema = {k:\"categorical\" if \"int\" in v.name else \"numeric\" for k, v in data_dict['dtypes'].items()}\n",
    "    profile = ProfileReport(df, title=\"Report\", type_schema=type_schema)#, minimal=True)\n",
    "    # export to json, html version of the report is to heavy and the browser crashes\n",
    "    report_json = profile.to_json()\n",
    "    report_dict = json.loads(report_json)\n",
    "    return report_dict, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "report_dict, report = make_report(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict[\"alerts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some alerts on correlation and imbalance:\n",
    "- Height **HWTDGHTM** is correlayed to weight **HWTDGHTM**, which also are correlated to the Body Mass Index **HWTDGBMI**\n",
    "- Daily smokers and non-smokers in **SMK_005** will be correlated to **SMK_010**: *In the past 30 days, did you smoke any cigarettes?* Other correlations have similar interpretations.\n",
    "- Imbalance **SMK_005** is intuitive, small percentage of the population smokes cigarettes.\n",
    "\n",
    "`var_map` dict contains a subset of the 67 columns based in the observations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib.use(\"QtAgg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the categorical features are on the var_map dictionary\n",
    "cat_cols = list(var_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two numerical columns are height and weight\n",
    "num_cols = [\"HWTDGHTM\", \"HWTDGWTK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert dictionaries to do the mapping from codes to names\n",
    "col_map_i = {}\n",
    "for k, v in var_map.items():\n",
    "    aux = {}\n",
    "    for kk, vv in v['var_map'].items():\n",
    "        aux[vv] = kk\n",
    "    col_map_i[k] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice columns of interest\n",
    "pre_df = df[num_cols+cat_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace values with string mappings\n",
    "pre_df.replace(col_map_i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ADM index\n",
    "pre_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change index name to ID\n",
    "pre_df.index.name = \"ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a column transformer, which will apply OrdinalEncoder to categorical features\n",
    "ct = make_column_transformer((OrdinalEncoder(dtype=int), cat_cols), ('passthrough', num_cols), verbose_feature_names_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want pandas dataframe output after transformation\n",
    "ct.set_output(transform=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_pre_df = ct.fit_transform(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.grid(False)\n",
    "sns.heatmap(fit_pre_df.corr(), square=True, linewidths=0.5, cmap=\"PiYG\", mask=np.triu(np.ones_like(fit_pre_df.corr(), dtype=bool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo pass the right type schema to generate the report\n",
    "profile = ProfileReport(fit_pre_df, title=\"Report\")#, type_schema=type_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the report can be heavy let's dump it in a dict\n",
    "report_json = profile.to_json()\n",
    "report_dict = json.loads(report_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict[\"alerts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save the first version of the cleaned preprocessed data\n",
    "cleaned_data = fit_pre_df.copy()\n",
    "cleaned_data.to_csv(f\"{data_path}/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split by provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inverse the transformation for categorical columns\n",
    "inverse_cleaned_data = pd.DataFrame(ct.transformers_[0][1].inverse_transform(cleaned_data[cat_cols]), columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_cleaned_data = cleaned_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get provinces codes\n",
    "provinces = province_cleaned_data[\"GEO_PRV\"].unique()\n",
    "provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get provinces names\n",
    "province_names = inverse_cleaned_data[\"GEO_PRV\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump csv files by province\n",
    "for p, pname in zip(provinces, province_names):\n",
    "    print(pname, p)\n",
    "    province_cleaned_data[province_cleaned_data[\"GEO_PRV\"]==p].to_csv(f\"{data_path}/{pname}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split by health regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{data_path}/regions\"): \n",
    "    # create the regions dir\n",
    "    os.makedirs(f\"{data_path}/regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get health regions codes\n",
    "regions = province_cleaned_data[\"GEODGHR4\"].unique()\n",
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get provinces names\n",
    "region_names = inverse_cleaned_data[\"GEODGHR4\"].unique()\n",
    "region_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump csv files by health regions\n",
    "for r, rname in zip(regions, region_names):\n",
    "    print(rname, r)\n",
    "    cleaned_name = \"\".join(i for i in rname if i not in \"\\/:*?<>=|.,()\").replace(\" \", \"_\").replace(\"’\",\"-\")\n",
    "    province_cleaned_data[province_cleaned_data[\"GEODGHR4\"]==r].to_csv(f\"{data_path}/regions/{cleaned_name}.csv\")\n",
    "    province_cleaned_data[province_cleaned_data[\"GEODGHR4\"]==r].to_csv(f\"{data_path}/regions/{r}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hRpl9Ctxxv8J"
   },
   "outputs": [],
   "source": [
    "# Data cleaning (not the selection of columns, but any other clearning steps)\n",
    "cleaned_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTGM-pvdrJie"
   },
   "outputs": [],
   "source": [
    "# Stratify into groups via column groupby\n",
    "stratified_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1VyuC-ZriEz"
   },
   "outputs": [],
   "source": [
    "# Stratify into groups via custom scheme\n",
    "# Specifically, specifyapproximate number of clients and clients get some number\n",
    "# of samples pulled from some distribution\n",
    "stratified_data = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yivfbt7KsDi8"
   },
   "source": [
    "Need to determine whether we want to generate the stratified datasets in a static way, then change the sample size, or vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtjP5mRUr57w"
   },
   "outputs": [],
   "source": [
    "# Update the number of samples to be used\n",
    "stratified_data = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FA2wUCUGsqqn"
   },
   "source": [
    "Note that data loading should not be done during each run, but rather be pre-generated and loaded appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RktzbO-RscZw"
   },
   "outputs": [],
   "source": [
    "# Select the column(s) to be used within the data\n",
    "stratified_data = stratified_data[...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbC7RDHMtAZu"
   },
   "outputs": [],
   "source": [
    "# Save dataset(s)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4upRBa30tpTF"
   },
   "outputs": [],
   "source": [
    "# Print data information\n",
    "# When called, provides information relevant to the provided data\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CHnE8vnt7hW"
   },
   "source": [
    "# Queries\n",
    "Code related to the statistal queries being run. This excludes any evaluations being done, only the queries themselves.\n",
    "Depending on the code structure for the DP libraries used, we may need to use different function calls for mean, sum, ... The mean, sum, and frequency functions should be abstracted such that the global DP file's functions can call them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tlyTGs3ub1A"
   },
   "outputs": [],
   "source": [
    "# Mean\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkWk9Elqu2xd"
   },
   "outputs": [],
   "source": [
    "# Sum\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2STdcotu4pr"
   },
   "outputs": [],
   "source": [
    "# Frequency\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVt9sjdOvXHo"
   },
   "outputs": [],
   "source": [
    "# Any others to add\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OGVGtdivaDg"
   },
   "source": [
    "# Evaluation\n",
    "Code which compare the results from queries and/or the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GHboZhLvnID"
   },
   "outputs": [],
   "source": [
    "# Explore the distribution of a provided dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yy8oA1Tdv8ye"
   },
   "outputs": [],
   "source": [
    "# Compare the distributions of two datasets\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HAdCWMxwCir"
   },
   "outputs": [],
   "source": [
    "# Compare the difference between two queries\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hljnbUlfwxkZ"
   },
   "source": [
    "# Local Differential Privacy\n",
    "Code exclusive for applying LDP on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6aPPaUWwMer"
   },
   "outputs": [],
   "source": [
    "# Function for generating each noise type, abstracting other parts (laplace, RR, ...)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-uF7DvixCXT"
   },
   "outputs": [],
   "source": [
    "# Function injecting the noise to the provided data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmpXiFFyxMek"
   },
   "source": [
    "# Global Differential Privacy\n",
    "Code exclusive for applying GDP on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RK7O5mwTxQFf"
   },
   "outputs": [],
   "source": [
    "# Differentially private queries (see Queries file section)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRpVKwMOx-7K"
   },
   "source": [
    "# Shuffle Differential Privacy\n",
    "Code exclusive for applying SDP on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pn5YpqlYx9ZO"
   },
   "outputs": [],
   "source": [
    "# Function to act as the shuffler\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7oqzw9LyPHn"
   },
   "source": [
    "# Model Tests\n",
    "Code exclusive fro testing DP applied to different models (wish list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnmOLLPXyUFu"
   },
   "outputs": [],
   "source": [
    "# Regression models\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6bzL-IzzEpc"
   },
   "outputs": [],
   "source": [
    "# ML models\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
